# llm configuration
gemini_api_key=AIzaSyD4NbYxbWOlvXPJhD_nSKQl1SjXAHxQtoc
gemini_model=gemini-2.5-pro

# vector database
pinecone_api_key=pcsk_33WkZZ_Gx2Ji5XWBgsHGZq84hMThYphnBZjWezz1RqmA1rUXCWkudg3zXDruMNYzYkas6A
pinecone_env=us-east-1-aws
pinecone_index_name=developer-quickstart-py

# application settings
debug=false
api_title=intelligent doc query system
api_version=1.0.0

# processing parameters
chunk_size=400
chunk_overlap=50
max_context_chunks=5
confidence_threshold=0.7

# server configuration
host=0.0.0.0
port=8000
workers=1