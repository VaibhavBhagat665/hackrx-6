# llm configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-pro

# vector database
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENV=your_pinecone_environment
PINECONE_INDEX=doc-index

# application settings
DEBUG=false
API_TITLE=intelligent doc query system
API_VERSION=1.0.0

# processing parameters
CHUNK_SIZE=400
CHUNK_OVERLAP=50
MAX_CONTEXT_CHUNKS=5
CONFIDENCE_THRESHOLD=0.7

# server configuration
HOST=0.0.0.0
PORT=8000
WORKERS=1
